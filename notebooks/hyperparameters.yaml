Logistic_Regression:
  C: [0.001, 0.01, 0.1, 1, 10, 100]
  class_weight: ['balanced', None]
Gaussian_NB:
  var_smoothing: [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11,
                  1e-12, 1e-13, 1e-14, 1e-15]
Bernoulli_NB:
  alpha: [0.0, 0.5, 1.0]
  binarize: [0.0, 0.5, 1.0]
  class_prior: [None, [.1,.9], [.2,.8], [.3,.7]]
Decision_Tree:
  max_depth: [2, 4, 6, 8, 10, None]
  min_samples_split: [2, 5, 10]
  min_samples_leaf: [1, 2, 4]
  class_weight: ['balanced', None]
Random_Forest:
  n_estimators: [10, 50, 100, 200]
  max_depth: [2, 4, 6, 8, 10, None]
  class_weight: ['balanced', 'balanced_subsample', None]
#Extra_Trees_Classifier:
#  n_estimators: [10, 50, 100, 200]
#  max_depth: [2, 4, 6, 8, 10, None]
#Ada_Boost:
#  n_estimators: [50, 100, 150]
#  learning_rate: [0.01, 0.1, 1, 10]
#Gradient_Boosting:
#  n_estimators: [50, 100, 150]
#  learning_rate: [0.01, 0.1, 1, 10]
#LightGBM:
#  n_estimators: [50, 100, 150]
#  learning_rate: [0.01, 0.1, 1, 10]
#Hist_GB:
#  max_iter: [50, 100, 150]
#XGBoost:
#  n_estimators: [50, 100, 150]
#  learning_rate: [0.01, 0.1, 1, 10]
